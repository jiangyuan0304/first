### subprocess 为啥是进程管理呢







threading

一个面向对象的高层api, 用于处理python 的并发性， Thread 对象在同一进程中并发的运行，并共享内存。对于IO受限而不是CPU受限的任务来说，使用

线程是这些任务实现缩放的一种简单方法



任何类型的对象都可以作为参数传递到线程

确定当前线程  threading.current_thread().getName()

​    

```python
import threading
import time

def worker():
    name = threading.current_thread().getName()
    print("{} :starting".format(name))
    time.sleep(2)
    print("{} :exiting".format(name))

def service():
    name = threading.current_thread().getName()
    print("{} :starting".format(name))
    time.sleep(2)
    print("{} :exiting".format(name))


a = threading.Thread(target=worker, name="Boss")
b = threading.Thread(target=worker)
c = threading.Thread(target=service, name="Boss-service")
# 如果我们对name 参数进行设置的话，就不会使用python默认的thead name
# 默认会根据线程启动的先后来命名

a.start()
b.start()
c.start()
```

```python
import threading
import time
import sys

def worker():
    time.sleep(2)
    # print(threading.current_thread().name)
    print(threading.current_thread().getName())
    sys.stdout.flush()


def spend_time(func):
    def wrapper():
        start_time = time.time()
        func()
        end_time = time.time()
        print('spend is {}'.format(end_time - start_time))

    return wrapper

# @showtime
# def five_worker():
#     for i in range(5):
#         worker()

@spend_time
def five_worker():
    threads = []
    for i in range(5):
            t = threading.Thread(target=worker)
            threads.append(t)
            t.start()

    for k in threads:
        k.join()
five_worker()

```

也可以使用logging 模块来调试，他支持将线程名嵌入到日志中去，业务上基本上使用这个来答应输出

#### 守护线程和非守护线程 

start()和join（） 方法要详细讲一下 join(timeout)

#### 枚举所有的线程

```python
import logging
import threading
import time
import random

logging.basicConfig(
    level=logging.DEBUG,
    format='[%(thread)d] [%(threadName)s] - %(message)s'
)

def worker():
    pause = random.randint(1, 5) / 10
    logging.debug("sleeping {}".format(pause))
    time.sleep(pause)
    logging.debug("ending")


for i in range(3):
    t = threading.Thread(target=worker)
    t.start()

print(threading.enumerate())
# main_thread = threading.main_thread()
# for t in threading.enumerate():
#     if t is main_thread:
#         continue
#     logging.debug("joining {}".format(t.getName()))
#     t.join()
```

https://www.cnblogs.com/cnkai/p/7504980.html

```python
import threading
import time

def run():
    time.sleep(2)
    print('当前线程的名字是： ', threading.current_thread().name)
    time.sleep(2)


if __name__ == '__main__':

    start_time = time.time()

    print('这是主线程：', threading.current_thread().name)
    thread_list = []
    for i in range(5):
        t = threading.Thread(target=run)
        thread_list.append(t)

    for t in thread_list:
        t.start()

    print('主线程结束！' , threading.current_thread().name)
    print('一共用时：', time.time()-start_time)
```



#### 什么是回调函数

为啥threading args 中需要用元组 且一个元素的时候需要一个逗号



#### 线程间传递信号

虽然多线程的目的是并发的运行单独的操作，但是也需要在多个线程间同步操作

#### Event

事件对象是一种线程间安全通信的简单方法。Event 对象管理的就是一个内部标志，我们可以用set() clear(）方法来控制它状态的变化

从而来达到线程间通信的目的             其他线程可以使用wait（） 暂停阻塞    clear()可以清楚状态

```python
import logging
import threading
import time

logging.basicConfig(
    level=logging.DEBUG,
    format='[%(threadName)s] - %(message)s'
)

def monkey(e):
    logging.debug("waiting for event starting")
    event_is_set = e.wait()
    logging.debug("event status is {},\
                  then start monkey work".format(event_is_set))

def autotest(e):
    logging.debug("start autotest task")
    time.sleep(5)
    e.set()
    logging.debug("autotest task ending")

e = threading.Event()

t = threading.Thread(
    target=monkey,
    name="monkey",
    args=(e,))
t.start()

k = threading.Thread(
    target=autotest,
    name="aiqiyi-test",
    args=(e,))
k.start()

```

#### Lock

当有重要数据进行修改的时候，如果多个操作同时进行难免会破坏或丢失数据，所以我们需要控制对共享资源的访问。达到安全访问一个对象的方式，就可以使用Lock对象 

顾名思义，大家都知道如果上了一把锁，只有拿到钥匙的人才能进去

```python
import logging
import random
import time
import threading

logging.basicConfig(
    level=logging.DEBUG,
    # format='[%(threadName)s] - %(message)s'
    format='进程：%(process)d 线程：[%(thread)d] - %(message)s'
)

class Counter():
    def __init__(self, start = 0):
        self.lock = threading.Lock()
        self.value = start

    def increament(self):
        logging.debug("waiting for lock")
        self.lock.acquire()
        try:
            logging.debug("acquired lock")
            self.value += 1
        finally:
            self.lock.release()

def worker(c):
    for i in range(2):
        pause = random.randint(1,4)
        logging.debug("sleeping {}".format(pause))
        time.sleep(pause)
        c.increament()
    logging.debug("Done")

count = Counter()
for i in range(2):
    t = threading.Thread(target=worker, args=(count, ))
    t.start()

main_thread = threading.main_thread()
for t in threading.enumerate():
    if t is not main_thread:
        t.join()

logging.debug('Counter {}'.format(count.value))

logging.debug("waiting for worker threads")
# 主线程用于执行 当前代码程序段


```



#### 锁作为上下文管理器

with 实现了__enter__  __exit__ 两个方法



#### condition 同步线程

出了上面说的event 来同步线程还可以用Condition对象来同步线程  ，由于Condition 使用了一个Lock 所以可以绑定到一个共享资源，允许多个线程等待资源更像，就像我们等待版本发布一样

```python
import  logging
import threading
import time


logging.basicConfig(
    level=logging.DEBUG,
    # format='[%(threadName)s] - %(message)s'
    format='进程：%(process)d 线程：[%(thread)d] - %(message)s'
)

def consumer(cond, name):
    logging.debug("[{}] waiting [release version]".format(name))
    with cond:
        # 为什么这么写
        cond.wait()
        logging.debug(" [{}] starting version check!!".format(name))

def producer(cond, name):
    logging.debug("starting produce thread ")
    with cond:
        logging.debug("[{}] makeing [release version]".format(name))
        time.sleep(2)
        cond.notifyAll()

cond = threading.Condition()

t1 = threading.Thread(target=consumer, name="C1", args=(cond, "小辉"))
t2 = threading.Thread(target=consumer, name="C2", args=(cond, "小明"))
p2 = threading.Thread(target=producer, name="p2", args=(cond, "小龙"))

t1.start()
time.sleep(2)
t2.start()
time.sleep(3)
p2.start()

```

#### semaphore

有时候是可以允许多个线程并发同时访问，但需要限制总数。像网络应用支持固定数据的并发下载 像lol 可以一个人玩，可以九个人玩一个挂机

https://www.jianshu.com/p/90d571c41895

> class threading.Semaphore([value])
> values是一个内部计数，values默认是1，如果小于0，则会抛出 ValueError 异常，可以用于控制线程数并发数

```python
import threading
import time

class RecordPool():
    def __init__(self):
        self.pool = list()
        self.lock = threading.Lock()

    def makeActive(self, name):
        with self.lock:
            self.pool.append(name)
            print("{} is running".format(self.pool))

    def inActive(self, name):
        with self.lock:
            self.pool.remove(name)
            print("{} is remove".format(name))

# def worker(sem, name):
#     with sem:
#         name = threading.current_thread().getName()
#         print("{} is working".format(name))
#         time.sleep(2)

def worker(s, pool):
    with s:
        name = threading.current_thread().name
        pool.makeActive(name)
        time.sleep(2)
        pool.inActive(name)

pool = RecordPool()
s = threading.Semaphore(3)
threads = list()
for i in range(10):
    t = threading.Thread(target=worker,
                         args=(s, pool),
                         name=str(i))
    threads.append(t)
    t.start()

```

继承也需要讲一下

#### 线程间得信息传递之deque

因为Python 内置得数据结构(列表，字典 )都是线程安全得，，这是Python 使用原子字节码来管理浙西而数据结果得一个副作用，（更新过程中不会释放保护Python 内部数据结构得全局解释锁GIL ）,但是像整数浮点数就没有这个保护

说一些列表和字典得一些更新操作



#### 线程优先级队列

线程池

#### Barrier

Barrier（）另一种同步机制 了解即可 像lol 必须得是个人才能开始，Barrier 就是等待十个人准备就绪这种状态完成，再往下执行





### multiprocessing

multiprocessing 模块包含一个api ，他是基于threading API 所以大部分方法相似 ，可以把工作划分打多个进程中去， 在IO 不密集的情况下是可以代替threading 模块来利用多个CPU内核的，但是也有不一样的地方

`multiprocessing`模块提供了一个`Process`类来代表一个进程对象，multiprocessing模块像线程一样管理进程，这个是multiprocessing的核心，它与threading很相似，对多核CPU的利用率会比threading好的多

确定当前进程 ，当我们去指定进程名的时候，对我们追踪进程特别有用

```python
import multiprocessing
import time
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format='进程：%(process)d 线程：[%(thread)d] - %(message)s'
)

def worker():
    logging.debug("worker {}".format(
        # multiprocessing.Process.name
        multiprocessing.current_process().name))
    time.sleep(1)


if __name__ == "__main__":
    # multiprocessing 对__main__使用了额外的保护，防止导入模块的时候在子进程中递归的调用 如果不写会报错
    jobs = []
    for i in range(5):
        p = multiprocessing.Process(name=str(i), target=worker )
        jobs.append(p)
        p.start()
```



派生进程了解即可，一般都是multiprocessing.Process() 创建，当然也可以使用一个定制的子类

???可以怎么定制呢

#### 守护进程

#### 进程等待Join

# 向进程传递消息

因为线程是共享内存的，所以传递消息比较方便。当工作划分到多个进程当中去的时候,如果像有效的利用多进程，通常要求他们呢之间有某种通信，这样才能分解工作，完成结果的聚集

一个简单的方法是Queue()

## JoinableQueue()

https://www.cnblogs.com/lilyxiaoyy/p/12389797.html      关于joinableQueue() 不太形象的例子

```

```

#### 

#### 进程间信号传输

event是一个简单方法，可以在进程之间传递状态信息，事件可以通过set() clear()  切换装填，wait()阻塞 is_set()查询状态信息

```python
import logging
import multiprocessing
import time

logging.basicConfig(
    level=logging.DEBUG,
    format='[%(threadName)s] - %(message)s'
)

def monkey(e):
    logging.debug("waiting for event starting")
    event_is_set = e.wait()
    logging.debug("event status is {},\
                  then start monkey work".format(event_is_set))

def autotest(e):
    logging.debug("start autotest task")
    time.sleep(5)
    e.set()
    logging.debug("autotest task ending")


if __name__ == "__main__":
    e = multiprocessing.Event()

    t = multiprocessing.Process(
        target=monkey,
        name="monkey",
        args=(e,)
    )
    t.start()

    k = multiprocessing.Process(
        target=autotest,
        name="aiqiyi-test",
        args=(e,)

    )
    k.start()

```

#### 

#### Lock

多个进程共享一个资源,那么在这种情况下，可以使用一个Lock来避免访问冲突



try except finally 掌握的也不是很好啊



#### Condition

#### semphore





进程池

对于资源有限情况下，且完成的工作可以分解并独立分布到多个工作进程时， 可以用Pool类来管理固定数目的工作进程，会收集各个作业的返回值并作为一个列表返回

> 若添加的任务数超出了设定的允许同时执行的最大任务数，则后续进程排队，待正在执行的子进程结束后进入执行（可以参考银行的多柜台排队，进程池设定的同时执行的子进程数量相当于银行的办理窗口，添加的进程相当于前往银行办理业务的客户，当客户数量超过了开放的窗口数，后续用户开始排队）

> **3.map()**
>
> 函数原型：map(func, iterable[, chunksize=None])
>
> Pool类中的map方法，与内置的map函数用法行为基本一致，它会使进程阻塞直到结果返回
> 注意：虽然第二个参数是一个迭代器，但在实际使用中，必须在整个队列都就绪后，程序才会运行子进程

```python
import multiprocessing

def cala(data):
    return data ** 2


def start_process():
    print("starting {}".format(multiprocessing.current_process().name))

if __name__ == "__main__":
    pool_size = multiprocessing.cpu_count()
    pool = multiprocessing.Pool(
        processes=pool_size,
        initializer=start_process,
    )

    pool_output = pool.map(cala, list(range(10)))
    pool.close()
    pool.join()
    print(pool_output)
```



遗留问题 JoinableQueue 和Queue的区别