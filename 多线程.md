





#### 什么是进程

进程是指在系统中正在运行的一个应用程序，程序一旦运行就是进程。

进程得特点：

1. 一个在内存中运行得应用程序就是一个进程，每个进程都有自己独立得内存空间（其实是拥有自己得虚拟地址，cpu 运行的时候会拿到内存中实际的地址）

   一个进程可以有多个线程，并且至少一个线程

2. 进程是资源分配的最小单位

3. 当一个可执行程序被系统执行（分配内存资源）就成了一个进程

#### 进程的几种状态：

- 运行状态 running   程序已分配cpu在执行机上正在执行
- 就绪状态 Ready  具备运行条件，但是此时其他进程正在占用CPU, 而不能运行等待运行的状态
- 阻塞状态 Blocked  等待某个输入 而暂时不能运行的状态，不同的是即使有空闲的CPU 也不能使用
- 新建状态 New  这个是刚刚被创建但未进入就绪状态的样子
- 终止状态 Terminated  正常终止或错误终止所处的状态

#### 什么是线程

线程是进程的一个实体，是进程的一条执行路径， 是cpu调度和分派的基本单位，他是比进程更小的独立运行单位，线程自己基本上不拥有系统资源，只拥有一点

在运行中必不可少的资源（如程序计数器，寄存器和栈），但是它与同属一个进程的其他线程共享进程所拥有的全部资源

#### 线程的特点

1. 负责当前进程中程序的执行，是进程中的一个执行任务，一个进程至少有一个线程， 也可以拥有多个线程，多个线程可以共享数据
2. 线程是操作系统调度的最小单位
3. 线程是进程的真正执行者，是一些指令的合集（进程是资源的拥有者）
4. 同一个进程下的多个线程共享内存空间，数据直接访问（数据共享）
5. 为保证数据安全，必须使用线程锁

#### 线程的状态：

​    参考进程的状态



### subprocess 为啥是进程管理呢



只讲下 执行shell 和命令交互



threading

一个面向对象的高层api, 用于处理python 的并发性， Thread 对象在同一进程中并发的运行，并共享内存。对于IO受限而不是CPU受限的任务来说，使用

线程是这些任务实现缩放的一种简单方法



任何类型的对象都可以作为参数传递到线程

确定当前线程  threading.current_thread().getName()

​    

```python
import threading
import time

def worker():
    name = threading.current_thread().getName()
    print("{} :starting".format(name))
    time.sleep(2)
    print("{} :exiting".format(name))

def service():
    name = threading.current_thread().getName()
    print("{} :starting".format(name))
    time.sleep(2)
    print("{} :exiting".format(name))


a = threading.Thread(target=worker, name="Boss")
b = threading.Thread(target=worker)
c = threading.Thread(target=service, name="Boss-service")
# 如果我们对name 参数进行设置的话，就不会使用python默认的thead name
# 默认会根据线程启动的先后来命名

a.start()
b.start()
c.start()
```

```python
import threading
import time
import sys

def worker():
    time.sleep(2)
    # print(threading.current_thread().name)
    print(threading.current_thread().getName())
    sys.stdout.flush()


def spend_time(func):
    def wrapper():
        start_time = time.time()
        func()
        end_time = time.time()
        print('spend is {}'.format(end_time - start_time))

    return wrapper

# @showtime
# def five_worker():
#     for i in range(5):
#         worker()

@spend_time
def five_worker():
    threads = []
    for i in range(5):
            t = threading.Thread(target=worker)
            threads.append(t)
            t.start()

    for k in threads:
        k.join()
five_worker()

```

也可以使用logging 模块来调试，他支持将线程名嵌入到日志中去，业务上基本上使用这个来答应输出

#### 守护线程和非守护线程 

start()和join（） 方法要详细讲一下 join(timeout)

#### 枚举所有的线程

```python
import logging
import threading
import time
import random

logging.basicConfig(
    level=logging.DEBUG,
    format='[%(thread)d] [%(threadName)s] - %(message)s'
)

def worker():
    pause = random.randint(1, 5) / 10
    logging.debug("sleeping {}".format(pause))
    time.sleep(pause)
    logging.debug("ending")


for i in range(3):
    t = threading.Thread(target=worker)
    t.start()

print(threading.enumerate())
# main_thread = threading.main_thread()
# for t in threading.enumerate():
#     if t is main_thread:
#         continue
#     logging.debug("joining {}".format(t.getName()))
#     t.join()
```

https://www.cnblogs.com/cnkai/p/7504980.html

```python
import threading
import time

def run():
    time.sleep(2)
    print('当前线程的名字是： ', threading.current_thread().name)
    time.sleep(2)


if __name__ == '__main__':

    start_time = time.time()

    print('这是主线程：', threading.current_thread().name)
    thread_list = []
    for i in range(5):
        t = threading.Thread(target=run)
        thread_list.append(t)

    for t in thread_list:
        t.start()

    print('主线程结束！' , threading.current_thread().name)
    print('一共用时：', time.time()-start_time)
```



#### 什么是回调函数

为啥threading args 中需要用元组 且一个元素的时候需要一个逗号



#### 线程间传递信号

虽然多线程的目的是并发的运行单独的操作，但是也需要在多个线程间同步操作

#### Event

事件对象是一种线程间安全通信的简单方法。Event 对象管理的就是一个内部标志，我们可以用set() clear(）方法来控制它状态的变化

从而来达到线程间通信的目的             其他线程可以使用wait（） 暂停阻塞    clear()可以清楚状态

```python
import logging
import threading
import time

logging.basicConfig(
    level=logging.DEBUG,
    format='[%(threadName)s] - %(message)s'
)

def monkey(e):
    logging.debug("waiting for event starting")
    event_is_set = e.wait()
    logging.debug("event status is {},\
                  then start monkey work".format(event_is_set))

def autotest(e):
    logging.debug("start autotest task")
    time.sleep(5)
    e.set()
    logging.debug("autotest task ending")

e = threading.Event()

t = threading.Thread(
    target=monkey,
    name="monkey",
    args=(e,))
t.start()

k = threading.Thread(
    target=autotest,
    name="aiqiyi-test",
    args=(e,))
k.start()

```

#### Lock

当有重要数据进行修改的时候，如果多个操作同时进行难免会破坏或丢失数据，所以我们需要控制对共享资源的访问。达到安全访问一个对象的方式，就可以使用Lock对象 

顾名思义，大家都知道如果上了一把锁，只有拿到钥匙的人才能进去

```python
import logging
import random
import time
import threading

logging.basicConfig(
    level=logging.DEBUG,
    # format='[%(threadName)s] - %(message)s'
    format='进程：%(process)d 线程：[%(thread)d] - %(message)s'
)

class Counter():
    def __init__(self, start = 0):
        self.lock = threading.Lock()
        self.value = start

    def increament(self):
        logging.debug("waiting for lock")
        self.lock.acquire()
        try:
            logging.debug("acquired lock")
            self.value += 1
        finally:
            self.lock.release()

def worker(c):
    for i in range(2):
        pause = random.randint(1,4)
        logging.debug("sleeping {}".format(pause))
        time.sleep(pause)
        c.increament()
    logging.debug("Done")

count = Counter()
for i in range(2):
    t = threading.Thread(target=worker, args=(count, ))
    t.start()

main_thread = threading.main_thread()
for t in threading.enumerate():
    if t is not main_thread:
        t.join()

logging.debug('Counter {}'.format(count.value))

logging.debug("waiting for worker threads")
# 主线程用于执行 当前代码程序段


```



#### 锁作为上下文管理器

with 实现了__enter__  __exit__ 两个方法

1. 可以以一种更加优雅的方式，操作（创建/获取/释放）资源，如文件操作、数据库连接；
2. 可以以一种更加优雅的方式，处理异常；

#### condition 同步线程

出了上面说的event 来同步线程还可以用Condition对象来同步线程  ，由于Condition 使用了一个Lock 所以可以绑定到一个共享资源，允许多个线程等待资源更像，就像我们等待版本发布一样

```python
import  logging
import threading
import time


logging.basicConfig(
    level=logging.DEBUG,
    # format='[%(threadName)s] - %(message)s'
    format='进程：%(process)d 线程：[%(thread)d] - %(message)s'
)

def consumer(cond, name):
    logging.debug("[{}] waiting [release version]".format(name))
    with cond:
        # 为什么这么写
        cond.wait()
        logging.debug(" [{}] starting version check!!".format(name))

def producer(cond, name):
    logging.debug("starting produce thread ")
    with cond:
        logging.debug("[{}] makeing [release version]".format(name))
        time.sleep(2)
        cond.notifyAll()

cond = threading.Condition()

t1 = threading.Thread(target=consumer, name="C1", args=(cond, "小辉"))
t2 = threading.Thread(target=consumer, name="C2", args=(cond, "小明"))
p2 = threading.Thread(target=producer, name="p2", args=(cond, "小龙"))

t1.start()
time.sleep(2)
t2.start()
time.sleep(3)
p2.start()

```

#### semaphore

有时候是可以允许多个线程并发同时访问，但需要限制总数。像网络应用支持固定数据的并发下载 像lol 可以一个人玩，可以九个人玩一个挂机

https://www.jianshu.com/p/90d571c41895

> class threading.Semaphore([value])
> values是一个内部计数，values默认是1，如果小于0，则会抛出 ValueError 异常，可以用于控制线程数并发数

```python
import threading
import time

class RecordPool():
    def __init__(self):
        self.pool = list()
        self.lock = threading.Lock()

    def makeActive(self, name):
        with self.lock:
            self.pool.append(name)
            print("{} is running".format(self.pool))

    def inActive(self, name):
        with self.lock:
            self.pool.remove(name)
            print("{} is remove".format(name))

# def worker(sem, name):
#     with sem:
#         name = threading.current_thread().getName()
#         print("{} is working".format(name))
#         time.sleep(2)

def worker(s, pool):
    with s:
        name = threading.current_thread().name
        pool.makeActive(name)
        time.sleep(2)
        pool.inActive(name)

pool = RecordPool()
s = threading.Semaphore(3)
threads = list()
for i in range(10):
    t = threading.Thread(target=worker,
                         args=(s, pool),
                         name=str(i))
    threads.append(t)
    t.start()

```

继承也需要讲一下

#### 线程间得信息传递之deque

因为Python 内置得数据结构(列表，字典 )都是线程安全得，，这是Python 使用原子字节码来管理浙西而数据结果得一个副作用，（更新过程中不会释放保护Python 内部数据结构得全局解释锁GIL ）,但是像整数浮点数就没有这个保护

最经典的就是生产者-消费者模型

说一些列表和字典得一些更新操作



#### 线程优先级队列

#### 线程池

减少线程创建及消毁过程中损失的计算资源正是线程池的意义所在

> https://www.jianshu.com/p/b9b3d66aa0be

```python
from concurrent.futures import ThreadPoolExecutor
import time

# 参数times用来模拟网络请求的时间
def get_html(times):
    time.sleep(times)
    print("get page {}s finished".format(times))
    return times
    
results = list()
with ThreadPoolExecutor(max_workers=2) as f:
    for i in range(3,5):
        results.append(f.submit(get_html, (i)))

    time.sleep(4)
    for k in results:
        print(k.result())
```



```python
from concurrent.futures import ThreadPoolExecutor
import time

# 参数times用来模拟网络请求的时间
def get_html(times):
    time.sleep(times)
    print("get page {}s finished".format(times))
    return times

executor = ThreadPoolExecutor(max_workers=2)
# 通过submit函数提交执行的函数到线程池中，submit函数立即返回，不阻塞
task1 = executor.submit(get_html, (3))
task2 = executor.submit(get_html, (2))
# done方法用于判定某个任务是否完成
print(task1.done())
# cancel方法用于取消某个任务,该任务没有放入线程池中才能取消成功
print(task2.cancel())
time.sleep(4)
print(task1.done())
# result方法可以获取task的执行结果
print(task1.result())

# 执行结果
# False  # 表明task1未执行完成
# False  # 表明task2取消失败，因为已经放入了线程池中
# get page 2s finished
# get page 3s finished
# True  # 由于在get page 3s finished之后才打印，所以此时task1必然完成了
# 3     # 得到task1的任务返回值
```



#### Barrier

Barrier（）另一种同步机制 了解即可 像lol 必须得是个人才能开始，Barrier 就是等待十个人准备就绪这种状态完成，再往下执行





### multiprocessing

multiprocessing 模块包含一个api ，他是基于threading API 所以大部分方法相似(可以说是threading 的镜像) ，可以把工作划分打多个进程中去， 在IO 不密集的情况下是可以代替threading 模块来利用多个CPU内核的，但是也有不一样的地方

`multiprocessing`模块提供了一个`Process`类来代表一个进程对象，multiprocessing模块像线程一样管理进程，这个是multiprocessing的核心，它与threading很相似，对多核CPU的利用率会比threading好的多

确定当前进程 ，当我们去指定进程名的时候，对我们追踪进程特别有用

```python
import multiprocessing
import time
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format='进程：%(process)d 线程：[%(thread)d] - %(message)s'
)

def worker():
    logging.debug("worker {}".format(
        # multiprocessing.Process.name
        multiprocessing.current_process().name))
    time.sleep(1)


if __name__ == "__main__":
    # multiprocessing 对__main__使用了额外的保护，防止导入模块的时候在子进程中递归的调用 如果不写会报错
    jobs = []
    for i in range(5):
        p = multiprocessing.Process(name=str(i), target=worker )
        jobs.append(p)
        p.start()
```



派生进程了解即可，一般都是multiprocessing.Process() 创建，当然也可以使用一个定制的子类

???可以怎么定制呢

#### 守护进程

#### 进程等待Join

# 向进程传递消息

因为线程是共享内存的，所以传递消息比较方便。当工作划分到多个进程当中去的时候,如果像有效的利用多进程，通常要求他们呢之间有某种通信，这样才能分解工作，完成结果的聚集

一个简单的方法是Queue()

## JoinableQueue()

https://www.cnblogs.com/lilyxiaoyy/p/12389797.html      关于joinableQueue() 不太形象的例子

```

```

#### 

#### 进程间信号传输

event是一个简单方法，可以在进程之间传递状态信息，事件可以通过set() clear()  切换装填，wait()阻塞 is_set()查询状态信息

```python
import logging
import multiprocessing
import time

logging.basicConfig(
    level=logging.DEBUG,
    format='[%(threadName)s] - %(message)s'
)

def monkey(e):
    logging.debug("waiting for event starting")
    event_is_set = e.wait()
    logging.debug("event status is {},\
                  then start monkey work".format(event_is_set))

def autotest(e):
    logging.debug("start autotest task")
    time.sleep(5)
    e.set()
    logging.debug("autotest task ending")


if __name__ == "__main__":
    e = multiprocessing.Event()

    t = multiprocessing.Process(
        target=monkey,
        name="monkey",
        args=(e,)
    )
    t.start()

    k = multiprocessing.Process(
        target=autotest,
        name="aiqiyi-test",
        args=(e,)

    )
    k.start()

```

#### 

#### Lock

多个进程共享一个资源,那么在这种情况下，可以使用一个Lock来避免访问冲突



try except finally 掌握的也不是很好啊



#### Condition

```python
import multiprocessing
import time

def stage_1(cond):
    name = multiprocessing.current_process().name
    with cond:
        print("{} done and ready for stage2".format(name))
        cond.notify_all()

def stage_2(cond):
    name = multiprocessing.current_process().name
    with cond:
        print("block for cond status change")
        cond.wait()
        print("{} running".format(name))


if __name__ == "__main__":
    cond = multiprocessing.Condition()
    s1 = multiprocessing.Process(
        target=stage_1,
        args=(cond,)
    )

    s2_list = [
        multiprocessing.Process(
            target=stage_2,
            args=(cond, ),
            name="stage2_{}".format(i)
        )
        for i in range(1, 3)
    ]

    for c in s2_list:
        c.start()
        time.sleep(1)
    s1.start()
    s1.join()

    for c in s2_list:
        c.join()
```



#### semphore





进程池

对于资源有限情况下，且完成的工作可以分解并独立分布到多个工作进程时， 可以用Pool类来管理固定数目的工作进程，会收集各个作业的返回值并作为一个列表返回

> 若添加的任务数超出了设定的允许同时执行的最大任务数，则后续进程排队，待正在执行的子进程结束后进入执行（可以参考银行的多柜台排队，进程池设定的同时执行的子进程数量相当于银行的办理窗口，添加的进程相当于前往银行办理业务的客户，当客户数量超过了开放的窗口数，后续用户开始排队）

> **3.map()**
>
> 函数原型：map(func, iterable[, chunksize=None])
>
> Pool类中的map方法，与内置的map函数用法行为基本一致，它会使进程阻塞直到结果返回
> 注意：虽然第二个参数是一个迭代器，但在实际使用中，必须在整个队列都就绪后，程序才会运行子进程

```python
import multiprocessing

def cala(data):
    return data ** 2


def start_process():
    print("starting {}".format(multiprocessing.current_process().name))

if __name__ == "__main__":
    pool_size = multiprocessing.cpu_count()
    pool = multiprocessing.Pool(
        processes=pool_size,
        initializer=start_process,
    )

    pool_output = pool.map(cala, list(range(10)))
    pool.close()
    pool.join()
    print(pool_output)
```



遗留问题 JoinableQueue 和Queue的区别